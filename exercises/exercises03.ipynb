{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea #3\n",
    "\n",
    "## El principito: regex y los $n$-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿listo para tu tercera tarea en Python? En esta ocasión analizaremos la historia del *Principito* por Antoine de Saint-Exupéry usando las herramientas de Python que hemos visto hasta el momento usando herramientas básicas de NLP.\n",
    "\n",
    "**NLP** o *Natural Language Processing* , es una rama de la inteligencia artificial y ciencia de la computación que se encarga de procesar y cuantificar grandes cantidades de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Principito\n",
      "\n",
      "Antoine De Saint Exupery\n",
      "\n",
      "Capítulo 1\n",
      "Cuando yo tenía seis años vi en un libro sobre la selva virgen que se\n",
      "titulaba \"Historias vividas\", una magnífica lámina. Representaba una\n",
      "serpiente boa que se tragaba a una fiera. Esta es la copia del dibujo.\n",
      "En el libro se afirmaba: \"La serpiente boa se traga su presa entera,\n",
      "sin masticarla. Luego ya no puede moverse y duerme durante los\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head -10 files/principito.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corre esta linea antes de empezar la tarea.\n",
    "# **** Es importante instalar desde 'pip' el paquete \n",
    "# unidecode si aún no lo tienes. Para esto, corre en la línea de\n",
    "# comandos:\n",
    "#          pip install unidecode\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def clean_book(file):\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        txtfile = f.read()\n",
    "    # Removemos acentos y ñ por n para hacer\n",
    "    # las búsquedas más faciles\n",
    "    return unidecode(txtfile).replace(\"\\n\", \" \")\n",
    "\n",
    "principito = clean_book(\"files/principito.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuántas veces se menciona `principito` en la lectura?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuáles son los verbos en [pretérito imperfecto](https://es.wikipedia.org/wiki/Pretérito_imperfecto) que más se mencionan en el principito? e.g., `jugaba`, `Miraba`, `hablaba`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Quiénes son los 10 personajes que más se mencionan? Asume que al mencionar un personaje se refiere a `el` o `la` seguido del personaje. e.g., `la flor`, `el farolero`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué se dice sobre las flores? Encuentra los adjetivos de `flores son (...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completa la frase: `La prueba de(...)queria un cordero`. ¿Qué va dentro de `(...)`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué tanto `...-dijo el principito`? e.g., \n",
    "`'-Tengo sed de esta agua -dijo el principito'`, `'-Tienen mucha prisa -dijo el principito`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El modelo $n$-gram\n",
    "\n",
    "En esta segunda parte de la tarea aplicaremos nuestros conocimiento de Python para implementar un modelo de machine learning aplicado a *NLP*: [$n$-grams](https://en.wikipedia.org/wiki/N-gram).\n",
    "\n",
    "La finalidad de un modelo $n$-gram es modelar una secuencia de $n$ elementos (palabras, en este caso) dada una muestra de texto. Para lograr esto, el modelo asume que la probabilidad del acontecimiento de una palabra, dada toda una historia de palabras que la preceden, es igual a la probabilidad de esa misma palabra dada las últimas $n$ palabras que se dijeron. Esto es,\n",
    "\n",
    "Dado un texto (o corpus) con $m$ palabras y $n \\leq m$,\n",
    "\n",
    "$$\n",
    "    \\mathbb P(W_m \\ | \\ W_{m-1}, W_{m-2}, \\ldots, W_{m-n+1}) = \\mathbb P(W_m \\ | \\  W_{m-1}, W_{m-2}, \\ldots, W_{1})\n",
    "$$\n",
    "\n",
    "Dado esto, vemos que un $1$-gram (o *unigram* asume que)\n",
    "$$\n",
    "\\mathbb P(X_m) = \\mathbb P(W_m \\ | \\  W_{m-1}, W_{m-2}, \\ldots, W_{1})\n",
    "$$\n",
    "\n",
    "un $2$-gram (o bigram), el cuál cumple la [propiedad de Markov](https://es.wikipedia.org/wiki/Cadena_de_Márkov), asume que,\n",
    "$$\n",
    "\\mathbb P(X_m \\ | \\ X_{m-1}) = \\mathbb P(W_m \\ | \\  W_{m-1}, W_{m-2}, \\ldots, W_{1})\n",
    "$$\n",
    "\n",
    "un $3$-gram,\n",
    "$$\n",
    "\\mathbb P(X_m \\ | \\ X_{m-1}, X_{m-2}) = \\mathbb P(W_m \\ | \\  W_{m-1}, W_{m-2}, \\ldots, W_{1})\n",
    "$$\n",
    "\n",
    "y así sucesivamente.\n",
    "\n",
    "Este modelo se usaba en algunas apps en para predecir texto a pesar de su (aparente) deficiente suposición. En esta tarea implementaremos nuestro propio modelo $n$-gram para poder hablar como el principito.\n",
    "\n",
    "Para lograr esto, no consideraremos ningún signo de puntuación dentro del cuento del principito, por lo que el primer paso será limpiar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "# El primer paso será eliminar cada signo de puntuación.\n",
    "principito = re.sub(\"[{}]\".format(punctuation), \"\", principito)\n",
    "# Paso siguiente será poner cada caractér en minúscula\n",
    "principito = principito.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram\n",
    "\n",
    "Calcula la probabilidad de cada una de las palabras:\n",
    "\n",
    "1) Crea la variable `tokens` la cual es una lista ordenada de las palabras dentro de la variable `principito`. Por ejemplo, si `principito = \"esta es la historia del principito\"`, `tokens` deberá ser `['esta', 'es', 'la', 'historia', 'del', 'principito']`\n",
    "\n",
    "2) crea la variable `gram1`: un diccionario cuya llave es una palabra dentro de tokens y su valor es la probabilidad de su ocurrencia. Hint: usa la función `Counter` para lograr esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asegurate de haber calculado correctamente las probabilidades. ¿Cuál es la suma de cada una de las probabilidades?\n",
    "\n",
    "**Nota:** de tener un número marginalmente por arriba del 1, e.g., `1.0000000000000335`, como resultado, esto se debe a un [Roundoff Error](http://mathworld.wolfram.com/RoundoffError.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuál es la probabilidad de que aparezca la palabra `principito` en el texto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuál es la probabilidad de la palabra `amigo` o `amigos` en el texto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuál es la probabilidad de la palabra `el principito` en el texto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuál es la probabilidad de la palabra `una flor` en el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribe la función `gram1prob` que tome una oración y un diccionario de probabilidades unigram, e.g. `gram1`, para calcular la probabilidad de la oración. **Hint** considera la función [`all`](https://docs.python.org/3/library/functions.html#all) para resolver el problema.\n",
    "\n",
    "```python\n",
    ">>> gram1prob(\"juez\", gram1)\n",
    "7.401924500370096e-05\n",
    "\n",
    ">>> gram1prob(\"el principito era\", gram1)\n",
    "1.8159962136265147e-06\n",
    "\n",
    ">>> gram1prob(\"un gran animal\", gram1)\n",
    "0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram1prob(sentence, gram):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram\n",
    "\n",
    "A diferencia del unigram, si $n \\geq 2$, rompemos con la supoción de independencia en las palabras. En esta segunda parte crearemos una función $bi$-gram $n=2$, esto es, supondremos que la probabilidad de una palabra está dada por la última escrita antes de esta. Por ejemplo, dada la oración\n",
    "\n",
    "**\"who controls the past controls the future who controls the present controls the past\"**, nuestros *bi*grams serían\n",
    "\n",
    "> \"who controls\"\n",
    "\n",
    "> \"controls the\"\n",
    "\n",
    "> \"the past\"\n",
    "\n",
    "> \"past controls\"\n",
    "\n",
    "> ...\n",
    "\n",
    "> \"controls the\"\n",
    "\n",
    "> \"the past\"\n",
    "\n",
    "Tu tarea será crear la función `gram2prob` que, dada una lista de tokens (lista ordenada de las palabras), nos regrese un diccionario con la probabilidad de cada segunda palabra dada la última. Cada llave será la palabra anterior y cada valor otro diccionario cuya llave es la palabra que sigue y su valor la probabilidad de ocurrencia.\n",
    "\n",
    "Por ejemplo, para el conjunto de palabras anterior, `gram2prob` nos debería regresar lo siguiente:\n",
    "```python\n",
    "defaultdict(list,\n",
    "            {'controls': {'the': 1.0},\n",
    "             'future': {'who': 1.0},\n",
    "             'past': {'controls': 1.0},\n",
    "             'present': {'controls': 1.0},\n",
    "             'the': {'future': 0.25, 'past': 0.5, 'present': 0.25},\n",
    "             'who': {'controls': 1.0}})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considera los hints dados en la siguiente función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def gram2prob(tokens):\n",
    "    # 1) Creamos un defaultdict vacio donde guardaremos\n",
    "    # cada \"primera\" palabra.\n",
    "    ngdict = defaultdict(list)\n",
    "    \n",
    "    # 2) Crea tus bigrams agrupando los términos adecuadamente. Guarda \n",
    "    # El resultado en la variable 'grams'\n",
    "    # Recuerda, si tokens son [x1, x2, x3, x4], nuestros grams serían\n",
    "    # [(x1, x2), (x2, x3), (x3, x4)].\n",
    "    #     Hint: usa la función zip. ¿Cómo agruparías la lista\n",
    "    #           de arriba usando zip?\n",
    "    grams = None\n",
    "    \n",
    "    # 3) Creamos un diccionario cuya llave es la palabra inicial\n",
    "    # y el valor la palabra subsecuente. Para lograr esto, ocuparemos\n",
    "    # 'ngdict', nuestro 'defaultdict'.\n",
    "    # Iteramos sobre cada 'gram' en la lista 'grams'.\n",
    "    # Recuerda que cada gram es un tuple con dos elementos.\n",
    "    # El primer elemento de 'gram' sería la llave y el segundo elemento\n",
    "    # el valor a agregar a la lista del gram dado.\n",
    "    # Al final del loop, deberías tener un diccionario cuyos valores\n",
    "    # es una lista de cada palabra a la llave dada.\n",
    "    # Por ejemplo: para los bigrams\"[(a, b), (b, c), (a, c), (b, b)]\".\n",
    "    # Este loop debería modificar a ngdict como:\n",
    "    # {a: [b, c], b: [c, b]}\n",
    "    \n",
    "    # 4) iteramos cada llave en ngdict.\n",
    "    # * Cuenta cuantos elementos se asocian a cada llave\n",
    "    #   dentro de ngdict(longitud de cada lista). Guarda este valor\n",
    "    #   dentro de la variable total_elements\n",
    "    # * Accede a cada lista dentro de ngdict y usa Counter para\n",
    "    #   contar el número de elementos únicos dentro de la lista.\n",
    "    #   modifica esta entrada de ngdict para reemplazar la lista\n",
    "    #   por el Counter\n",
    "    # * Calcula la probabiliad de ocurrencia de cada elemento del contador\n",
    "    #   para cada llave dada creando un diccionario:\n",
    "    #   Itera  sobre cada palabra palabra del contador, accede a su elemento\n",
    "    #   y divídelo entre la variable total_elements. Crea un nuevo diccionario\n",
    "    #   con esto anterior y reemplaza el Contador que asignamos en el paso anterior.\n",
    "    \n",
    "    return ngdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corre esta línea para usar tu función sobre \"tokens\".\n",
    "gram2 = gram2prob(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuáles son las probabilidades de cada posible palabra dada `dijo`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
